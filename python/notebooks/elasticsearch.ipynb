{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/anuran/.local/lib/python3.10/site-packages (3.6.2)\n",
      "Requirement already satisfied: joblib in /home/anuran/.local/lib/python3.10/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /home/anuran/.local/lib/python3.10/site-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: tqdm in /home/anuran/.local/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: regex in /home/anuran/.local/lib/python3.10/site-packages (from nltk) (2023.6.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "\n",
    "# nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in /home/anuran/.local/lib/python3.10/site-packages (3.4.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/anuran/.local/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/anuran/.local/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/anuran/.local/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/anuran/.local/lib/python3.10/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy) (59.6.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/anuran/.local/lib/python3.10/site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: jinja2 in /home/anuran/.local/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/anuran/.local/lib/python3.10/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/anuran/.local/lib/python3.10/site-packages (from spacy) (1.0.9)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Using cached pydantic-1.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /home/anuran/.local/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/anuran/.local/lib/python3.10/site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/anuran/.local/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/anuran/.local/lib/python3.10/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/anuran/.local/lib/python3.10/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/anuran/.local/lib/python3.10/site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/anuran/.local/lib/python3.10/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/anuran/.local/lib/python3.10/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/anuran/.local/lib/python3.10/site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/anuran/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/anuran/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/anuran/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anuran/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/anuran/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/anuran/.local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/anuran/.local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/anuran/.local/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/anuran/.local/lib/python3.10/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Installing collected packages: pydantic\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.0.3\n",
      "    Uninstalling pydantic-2.0.3:\n",
      "      Successfully uninstalled pydantic-2.0.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "qdrant-client 1.1.7 requires urllib3<2.0.0,>=1.26.14, but you have urllib3 2.0.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pydantic-1.10.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 21:28:54.945749: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-21 21:28:55.143154: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-21 21:28:55.144319: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-21 21:28:56.834195: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-07-21 21:28:58.866796: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-21 21:28:59.010796: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.2721e+00 -1.9561e+00 -1.2942e-01 -1.4157e+00  6.0813e-02 -4.4143e-01\n",
      "  1.3058e+00 -4.4678e-01 -1.1243e+00  1.4385e+00  1.2475e+00  1.3509e-01\n",
      " -3.9008e+00 -7.8819e-01  3.1437e+00 -4.8362e+00  3.9010e+00 -3.7436e+00\n",
      "  3.9761e+00  8.2754e-01 -3.5623e+00  2.8127e-01  2.4718e+00 -2.8611e+00\n",
      " -2.2775e+00  3.2295e+00  8.0338e-01  1.0557e+00 -2.5407e+00  2.2598e+00\n",
      "  3.7579e+00 -2.7133e+00 -2.1832e+00 -3.1910e+00  6.2495e-01 -3.2630e-01\n",
      " -4.2565e+00 -5.5723e-01 -2.4663e-01 -1.2332e+00  6.1171e-01  1.4365e+00\n",
      "  5.2169e-01 -5.2224e-01  9.1337e-01 -2.2037e+00  7.3255e-01  2.5955e+00\n",
      " -3.9942e+00 -1.8513e-02  2.6387e+00 -2.5995e+00 -1.1057e+00  2.4968e-01\n",
      " -7.8866e-01  2.1814e+00 -6.3433e-01 -2.2497e+00 -1.1079e+00 -1.9684e+00\n",
      "  1.3503e+00  3.5277e+00  4.5623e+00  2.4652e-01 -2.2188e+00  4.3254e+00\n",
      " -6.0641e+00 -6.6332e+00 -3.1998e+00  2.3260e+00  9.4557e-01 -2.8268e+00\n",
      " -9.8059e-01 -6.4051e+00  1.0952e+00  2.9890e+00  1.7081e+00  1.3387e+00\n",
      "  4.7038e+00 -2.0743e+00  2.0295e+00 -1.1948e+00 -1.4421e+00 -1.8452e+00\n",
      "  1.9185e+00 -1.2763e+00  4.6222e+00  1.5113e+00  2.7768e-01 -1.3762e-01\n",
      " -9.2666e-01  5.4632e+00  2.7114e+00 -1.0975e+00 -9.3271e-02 -1.3775e+00\n",
      "  7.9205e-01  1.5419e+00 -2.1076e+00 -2.2726e+00 -1.0483e-01  3.9572e-01\n",
      "  4.1661e+00 -8.0936e-02 -2.0739e+00  1.9504e+00 -2.5855e+00  3.1556e+00\n",
      " -1.4201e-01  2.9916e+00  6.1123e+00  2.7229e-01 -2.1869e+00 -3.5002e-01\n",
      " -1.6976e+00  2.4952e+00  1.5532e+00 -3.9161e+00  9.9902e-01 -6.2457e-02\n",
      " -6.5284e+00  9.0174e-02 -1.5448e-01  5.0516e+00  2.5378e+00  5.5116e+00\n",
      " -1.3211e+00 -3.7213e-01  4.7793e+00 -1.6193e+00 -3.6727e+00 -1.3403e+00\n",
      " -6.7586e-01  4.5703e-01  1.7599e+00 -2.4716e+00  5.3457e-01  2.8008e+00\n",
      "  4.4503e+00 -1.1403e+00  9.5820e-01  1.6975e+00  1.2437e+00  1.1625e+00\n",
      " -5.0107e+00 -2.2322e+00  4.7536e+00  1.3612e+00 -4.0802e+00 -2.2705e-01\n",
      "  2.7132e+00  3.2399e+00 -1.7615e+00  2.6093e-01 -2.2009e+00 -1.7790e+00\n",
      "  5.8045e+00  1.3780e+00 -8.6540e-02 -1.9647e+00  1.4390e+00  1.6282e+00\n",
      " -2.3985e+00 -2.0655e+00 -2.3784e+00 -8.2443e-01  1.9355e+00 -2.3245e+00\n",
      " -1.9902e+00 -4.0677e-01  1.0489e+00 -4.8966e-01 -4.2944e-01  1.9128e+00\n",
      " -4.6330e+00  6.7349e-01 -3.4516e+00  8.6268e-01 -2.1172e+00 -2.1967e+00\n",
      "  1.3972e+00 -3.7369e-01  6.1528e+00 -4.3177e+00  3.3264e+00 -4.1691e+00\n",
      " -1.5937e+00 -2.9098e+00  3.8165e+00  1.2367e+00 -2.1695e+00  3.5159e+00\n",
      " -3.8814e+00  3.9892e-01 -2.7250e+00  2.7336e+00  5.6855e+00  3.3629e+00\n",
      " -6.4864e-01  8.2589e-01 -3.6074e+00  2.9264e+00 -2.6887e+00  4.6466e-01\n",
      "  3.0335e+00 -2.7201e+00  1.3247e+00 -9.9166e-02 -8.9032e-02  6.7374e-01\n",
      " -7.1058e-01  3.8612e-02  6.0284e+00 -1.4633e+00  1.9946e+00 -1.0521e-01\n",
      "  1.3082e+00 -1.1862e+00 -2.6551e+00 -4.7178e-01  3.7576e+00  2.9845e+00\n",
      "  7.4933e-03  1.9135e+00  1.2109e+00  2.7931e+00  5.4788e+00 -3.8904e+00\n",
      "  2.4089e+00  2.6360e-01 -4.4059e+00  2.5655e+00 -3.1885e-01 -4.9049e+00\n",
      "  7.1978e-01  6.6822e-01  1.7947e+00  1.0371e+00 -5.0491e-02  2.1638e-01\n",
      " -1.2181e+00 -7.9262e+00  9.1347e-01  9.8465e-01  4.2789e-01 -1.0945e-01\n",
      " -1.5694e+00  3.5739e-01 -3.6299e+00  2.4314e-01  3.2791e+00  1.5216e+00\n",
      " -3.0286e+00 -2.0603e+00  1.3856e-01 -4.4399e+00  4.0400e+00  1.8502e+00\n",
      " -2.3493e+00  2.6607e+00 -1.9802e+00 -2.5714e-01 -6.5082e-01  1.2268e+00\n",
      "  7.1316e-01  2.7335e+00 -2.8316e+00  1.4479e+00 -2.7933e+00  1.3094e+00\n",
      " -4.2391e+00  8.8205e-01  1.1506e+00 -3.4433e+00  6.9317e+00 -6.7787e+00\n",
      " -1.0737e+00 -1.2765e+00 -1.6900e+00  3.3909e+00  1.5821e+00 -1.2500e+00\n",
      " -1.7975e+00 -4.1718e+00  7.4848e-01  2.1253e-02  1.9433e+00 -3.4571e+00\n",
      " -1.1584e+00  5.6565e-01  2.2233e+00 -6.6398e-01  9.6524e+00  5.0152e-01\n",
      " -4.0495e-01 -1.5394e+00 -3.6646e+00  2.4781e+00 -7.1313e+00 -4.7342e+00]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# installation\n",
    "# python3 -m spacy download en_core_web_leg\n",
    "\n",
    "# Python minimal script\n",
    "nlp = spacy.load(\"en_core_web_lg\")  # the pretrained model\n",
    "doc = nlp(\"Here is my sentence!\")\n",
    "print(doc[0].vector)  # print the embedder of the first word (index 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SentenceTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence_transformers in /home/anuran/.local/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: sentencepiece in /home/anuran/.local/lib/python3.10/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: tqdm in /home/anuran/.local/lib/python3.10/site-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torchvision in /home/anuran/.local/lib/python3.10/site-packages (from sentence_transformers) (0.12.0)\n",
      "Requirement already satisfied: nltk in /home/anuran/.local/lib/python3.10/site-packages (from sentence_transformers) (3.6.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/anuran/.local/lib/python3.10/site-packages (from sentence_transformers) (0.14.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/anuran/.local/lib/python3.10/site-packages (from sentence_transformers) (1.11.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/anuran/.local/lib/python3.10/site-packages (from sentence_transformers) (4.29.2)\n",
      "Requirement already satisfied: scipy in /home/anuran/.local/lib/python3.10/site-packages (from sentence_transformers) (1.8.1)\n",
      "Requirement already satisfied: scikit-learn in /home/anuran/.local/lib/python3.10/site-packages (from sentence_transformers) (1.1.3)\n",
      "Requirement already satisfied: numpy in /home/anuran/.local/lib/python3.10/site-packages (from sentence_transformers) (1.23.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/anuran/.local/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/anuran/.local/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
      "Requirement already satisfied: fsspec in /home/anuran/.local/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2022.11.0)\n",
      "Requirement already satisfied: requests in /home/anuran/.local/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: filelock in /home/anuran/.local/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.8.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/anuran/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/anuran/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
      "Requirement already satisfied: joblib in /home/anuran/.local/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /home/anuran/.local/lib/python3.10/site-packages (from nltk->sentence_transformers) (8.1.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/anuran/.local/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/anuran/.local/lib/python3.10/site-packages (from torchvision->sentence_transformers) (9.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anuran/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/anuran/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/anuran/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/anuran/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "embedder = SentenceTransformer('bert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedder.encode(\"Hello there!\", convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing around with ELK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Creating the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "client = Elasticsearch(\n",
    "#     # \"https://first-elastic-cloud-deployment.es.ap-south-1.aws.elastic-cloud.com\",\n",
    "#     cloud_id=\"first-elastic-cloud-deployment:YXAtc291dGgtMS5hd3MuZWxhc3RpYy1jbG91ZC5jb206NDQzJGIxMTM4YmNlNjU5NjQ2ZDhhNWY3ZmY1ZTdkMzM3NjU1JGRiOWJkNDQ0MzFiODQ1OGU4MTg1MGUxZWU3ZGFhODk4\",\n",
    "#     api_key=(\"Elastic.co API Key\", \"UDZHN1NvZ0JHeFRLNXZ2ZEtNRHg6VTFvTk1xY0NUMUtXWURyczNTNWFzZw==\")\n",
    "# )\n",
    "# \"https://6v0z0skrmr:m9qbspe27d@vectorsearch-demo-4233748040.us-east-1.bonsaisearch.net:443\")\n",
    "\"http://localhost:9200\")\n",
    "client.info()\n",
    "\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        # \"dynamic\": True,\n",
    "        # \"_source\": {\n",
    "        #     \"enabled\": True\n",
    "        # },\n",
    "        \"properties\": {\n",
    "            \"user_id\": {\n",
    "                \"type\": \"unsigned_long\" \n",
    "            },\n",
    "            \"content\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"content_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"l2_norm\"\n",
    "            },\n",
    "            \"content_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"l2_norm\"\n",
    "            },\n",
    "            \"response\": {\n",
    "                \"type\": \"text\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "client = Elasticsearch(\n",
    "#     # \"https://first-elastic-cloud-deployment.es.ap-south-1.aws.elastic-cloud.com\",\n",
    "#     cloud_id=\"first-elastic-cloud-deployment:YXAtc291dGgtMS5hd3MuZWxhc3RpYy1jbG91ZC5jb206NDQzJGIxMTM4YmNlNjU5NjQ2ZDhhNWY3ZmY1ZTdkMzM3NjU1JGRiOWJkNDQ0MzFiODQ1OGU4MTg1MGUxZWU3ZGFhODk4\",\n",
    "#     api_key=(\"Elastic.co API Key\", \"UDZHN1NvZ0JHeFRLNXZ2ZEtNRHg6VTFvTk1xY0NUMUtXWURyczNTNWFzZw==\")\n",
    "# )\n",
    "# \"https://6v0z0skrmr:m9qbspe27d@vectorsearch-demo-4233748040.us-east-1.bonsaisearch.net:443\")\n",
    "\"http://localhost:9200\")\n",
    "\n",
    "mayoclinic_mappings = {\n",
    "    \"mappings\": {\n",
    "        # \"dynamic\": True,\n",
    "        # \"_source\": {\n",
    "        #     \"enabled\": True\n",
    "        # },\n",
    "        \"properties\": {\n",
    "            # \"user_id\": {\"type\": \"unsigned_long\"},\n",
    "            \"Name\": {\"type\": \"text\"},\n",
    "            \"Overview\": {\"type\": \"text\"},\n",
    "            \"Symptoms\": {\"type\": \"text\"},\n",
    "            \"Causes\": {\"type\": \"text\"},\n",
    "            \"Complications\": {\"type\": \"text\"},\n",
    "            \"Prevention\": {\"type\": \"text\"},\n",
    "            \"Related\": {\"type\": \"text\"},\n",
    "            \"Risk_factors\": {\"type\": \"text\"},\n",
    "            \"Types\": {\"type\": \"text\"},\n",
    "            \"Name_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"l2_norm\",\n",
    "            },\n",
    "            \"Overview_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"l2_norm\",\n",
    "            },\n",
    "            \"Symptoms_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"l2_norm\",\n",
    "            },\n",
    "            \"Causes_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"l2_norm\",\n",
    "            },\n",
    "            \"Complications_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"l2_norm\",\n",
    "            },\n",
    "            \"Prevention_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"l2_norm\",\n",
    "            },\n",
    "            \"Related_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"l2_norm\",\n",
    "            },\n",
    "            \"Risk_factors_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"l2_norm\",\n",
    "            },\n",
    "            \"Types_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"l2_norm\",\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = client.indices.create(\n",
    "    index=\"mayoclinic_index\",\n",
    "    body=mayoclinic_mappings,\n",
    "    ignore=400 # ignore 400 already exists code\n",
    ")\n",
    "\n",
    "documents = json.loads(open(\"/media/anuran/Samsung_SSD_970_EVO_1TB/Hackathons/Bajaj HackRx Prep/python/data/csvjson.json\", \"r\").read())\n",
    "\n",
    "new_docs = list(map(lambda doc: doc | {f\"{key}_vector\": embedder.encode(value) for key, value in doc.items() if isinstance(value, str)}, documents))\n",
    "# new_docs[0]\n",
    "import json\n",
    "# print(json.dumps(documents[2], indent=4))\n",
    "from elasticsearch import helpers\n",
    "from typing import Any\n",
    "\n",
    "def send_to_elasticsearch(client, documents: dict[str, Any], index: str) -> Any:\n",
    "    response = helpers.bulk(\n",
    "        client,\n",
    "        documents,\n",
    "        index=index\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# send_to_elasticsearch(client, new_docs, index=\"mayoclinic_index\")\n",
    "\n",
    "def vector_search(client, content_vector: list[float], index: str, field: str) -> list[dict]:\n",
    "    script_query = {\n",
    "        \"knn\":{\n",
    "            \"k\": 10,\n",
    "            \"num_candidates\": 10,\n",
    "            \"field\": field,\n",
    "            \"query_vector\": content_vector\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = client.knn_search(\n",
    "        body=script_query,\n",
    "        index=index,\n",
    "    )[\"hits\"][\"hits\"]\n",
    "    \n",
    "    return response\n",
    "\n",
    "# new_docs[0][\"Symptoms_vector\"]\n",
    "# vector_search(client, content_vector=new_docs[0][\"Symptoms_vector\"], index=\"mayoclinic_index\", field=\"Symptoms_vector\")\n",
    "def total_search(content_vector: list[float], fields=[], threshold: float=0.6, index=\"mayoclinic_index\"):\n",
    "    all_results: list[dict] = []\n",
    "\n",
    "    for field in fields:\n",
    "        all_results += vector_search(client, content_vector=content_vector, index=index, field=f\"{field}_vector\")\n",
    "\n",
    "    return list(filter(lambda doc: doc[\"_score\"] > threshold, all_results))\n",
    "\n",
    "res = total_search(fields=[\n",
    "    \"Overview\",\n",
    "    \"Symptoms\",\n",
    "    \"Causes\",\n",
    "    \"Complications\",\n",
    "    \"Prevention\",\n",
    "    \"Related\",\n",
    "    \"Risk_factors\",\n",
    "    \"Types\"\n",
    "], content_vector=new_docs[0][\"Symptoms_vector\"])\n",
    "\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/media/anuran/Samsung_SSD_970_EVO_1TB/Hackathons/Bajaj HackRx Prep/python/notebooks/frugalgpt_imp.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/anuran/Samsung_SSD_970_EVO_1TB/Hackathons/Bajaj%20HackRx%20Prep/python/notebooks/frugalgpt_imp.ipynb#X33sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m helpers\u001b[39m.\u001b[39mscan(\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/anuran/Samsung_SSD_970_EVO_1TB/Hackathons/Bajaj%20HackRx%20Prep/python/notebooks/frugalgpt_imp.ipynb#X33sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m         client,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/anuran/Samsung_SSD_970_EVO_1TB/Hackathons/Bajaj%20HackRx%20Prep/python/notebooks/frugalgpt_imp.ipynb#X33sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m         index\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmy_doc_dense_index\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/anuran/Samsung_SSD_970_EVO_1TB/Hackathons/Bajaj%20HackRx%20Prep/python/notebooks/frugalgpt_imp.ipynb#X33sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m         }\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/anuran/Samsung_SSD_970_EVO_1TB/Hackathons/Bajaj%20HackRx%20Prep/python/notebooks/frugalgpt_imp.ipynb#X33sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/anuran/Samsung_SSD_970_EVO_1TB/Hackathons/Bajaj%20HackRx%20Prep/python/notebooks/frugalgpt_imp.ipynb#X33sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m search_document \u001b[39m=\u001b[39m documents[\u001b[39m2\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/anuran/Samsung_SSD_970_EVO_1TB/Hackathons/Bajaj%20HackRx%20Prep/python/notebooks/frugalgpt_imp.ipynb#X33sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDocument will find relevant queries for: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msearch_document[\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/anuran/Samsung_SSD_970_EVO_1TB/Hackathons/Bajaj%20HackRx%20Prep/python/notebooks/frugalgpt_imp.ipynb#X33sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m search_results \u001b[39m=\u001b[39m vector_search(client, content_vector\u001b[39m=\u001b[39msearch_document[\u001b[39m\"\u001b[39m\u001b[39mcontent_vector\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/anuran/Samsung_SSD_970_EVO_1TB/Hackathons/Bajaj%20HackRx%20Prep/python/notebooks/frugalgpt_imp.ipynb#X33sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m search_results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(search_results)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'content'"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "import requests\n",
    "from elasticsearch import helpers\n",
    "\n",
    "def send_to_elasticsearch(client, documents: dict[str, Any], index: str) -> Any:\n",
    "    response = helpers.bulk(\n",
    "        client,\n",
    "        documents,\n",
    "        index=index\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def vector_search(client, content_vector: list[float]) -> dict:\n",
    "    script_query = {\n",
    "        \"knn\":{\n",
    "            \"k\": 10,\n",
    "            \"num_candidates\": 10,\n",
    "            \"field\": \"content_vector\",\n",
    "            \"query_vector\": content_vector\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = client.knn_search(\n",
    "        body=script_query,\n",
    "        index=\"my_doc_dense_index\"\n",
    "    )[\"hits\"][\"hits\"]\n",
    "    \n",
    "    return response\n",
    "\n",
    "def find_document_by_id(client, doc_id: Any) -> dict:\n",
    "    return helpers.scan(\n",
    "        client,\n",
    "        index=\"my_doc_dense_index\",\n",
    "        query={\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    \"_id\": doc_id\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "search_document = documents[2]\n",
    "\n",
    "\n",
    "print(f\"Document will find relevant queries for: \\n\\n{search_document['content']}\\n\\n\")\n",
    "\n",
    "\n",
    "search_results = vector_search(client, content_vector=search_document[\"content_vector\"])\n",
    "\n",
    "search_results = list(search_results)\n",
    "\n",
    "# for i in search_results:\n",
    "#     print(i)\n",
    "\n",
    "if len(search_results) == 0:\n",
    "    send_to_elasticsearch(client, documents, index=\"my_doc_dense_index\")\n",
    "if len(search_results) > 0:\n",
    "    print(\"Search results = \", json.dumps({\"similarity_score\": search_results[0][\"_score\"], \"question\": search_results[0][\"_source\"][\"content\"]}, indent=4))\n",
    "    required_doc = list(find_document_by_id(client, search_results[0][\"_id\"]))[0]\n",
    "    # for i in required_doc:\n",
    "    #     print(json.dumps(i[\"_source\"][\"content\"], indent=4))\n",
    "    print(\"\\n\\n\", json.dumps(required_doc[\"_source\"][\"content\"], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_index': 'my_doc_dense_index', '_id': 'l1nsTYgBX22roxooNDq-', '_score': None, '_source': {'user_id': 1, 'content': 'Tell me about Jeff Bezos', 'content_vector': [0.11726119369268417, 0.9716929793357849, 0.5266608595848083, -0.3831287920475006, 0.6973549723625183, 0.806764543056488, -0.7969883680343628, -0.07402234524488449, -0.35865962505340576, 0.11552295088768005, 0.3797169327735901, 0.8005709052085876, -0.13412420451641083, -0.059436358511447906, -1.0270061492919922, 0.14987871050834656, -0.6999553442001343, -0.10580424219369888, 0.9898144602775574, -0.012892406433820724, 0.43448787927627563, -0.7498344779014587, -0.3918928802013397, -0.04985924810171127, 0.830612063407898, 0.6233725547790527, 0.2736530303955078, -0.5112922191619873, -0.5562454462051392, 0.030531881377100945, -0.8354816436767578, -0.13772821426391602, 0.3491499423980713, -0.13309898972511292, -1.7290396690368652, 0.40402278304100037, -0.9289469122886658, -0.42089855670928955, -0.816062331199646, 0.12599043548107147, 0.5980026125907898, -0.6341882944107056, 0.12022998929023743, 0.13117122650146484, -0.9104452133178711, 0.1365104466676712, -0.13617464900016785, 0.37487685680389404, -0.5397809743881226, -0.3960232436656952, -0.8538506031036377, -0.4801190495491028, -1.5425128936767578, -0.17629238963127136, -0.560421347618103, -0.4155009984970093, 0.33131447434425354, -0.7592410445213318, -0.04659717530012131, 0.6485843658447266, 0.5596136450767517, -0.24731242656707764, 0.6466989517211914, 0.39104652404785156, 0.4475385546684265, -0.04341679438948631, 0.37981849908828735, -0.6042011380195618, -0.20578278601169586, 1.0776687860488892, 1.415428876876831, -0.3308706283569336, -0.023945674300193787, 1.3938100337982178, -0.8070846796035767, -0.013817965984344482, 0.3197873830795288, 0.49438464641571045, 0.23454247415065765, 0.3106535077095032, 0.5084269046783447, -0.13571500778198242, 1.0150716304779053, 0.13846445083618164, -0.0660509392619133, -0.6457756757736206, 0.22753611207008362, 0.1585921198129654, -0.5543402433395386, 0.03085257112979889, -0.5865060091018677, -0.25390318036079407, 0.46716684103012085, 0.4838559925556183, 0.74884033203125, -1.0166645050048828, -0.06109221652150154, 0.18907389044761658, -0.7681970596313477, -0.6039720773696899, 0.05717378482222557, -0.17732670903205872, -0.5259672403335571, 0.02222532033920288, 0.17469754815101624, 0.044981349259614944, 0.15484923124313354, 0.5354714393615723, 0.32625314593315125, -0.23908594250679016, 0.14591170847415924, 0.2201663702726364, 0.44750720262527466, 0.506170928478241, 0.32511669397354126, -0.7060955762863159, -0.10831128060817719, 0.8460988998413086, -0.6608974933624268, -0.43629223108291626, 0.16987952589988708, 1.7661675214767456, -0.1940326690673828, -0.5306544303894043, 1.4864600896835327, -0.2734883725643158, -0.25720542669296265, 0.1859813928604126, 0.051863446831703186, 0.07848528772592545, 0.4310038089752197, -0.4595029950141907, 0.5892291069030762, -0.2356320172548294, -0.1300554871559143, 0.19643843173980713, -0.33687877655029297, -0.7491285800933838, 0.03173695132136345, -0.03172074258327484, 0.3915420174598694, -0.19372671842575073, -0.7121613621711731, 0.12415847927331924, -0.6523537635803223, -0.6819929480552673, 0.1810624897480011, 0.9098237752914429, -0.4259699285030365, 0.8652069568634033, 0.6132022142410278, 1.2284749746322632, -1.169024109840393, -0.7383534908294678, 0.27880650758743286, 0.7432876825332642, -0.2779201567173004, -0.30602365732192993, 0.2968710660934448, 0.048512980341911316, -0.023152317851781845, 0.4520648121833801, -0.17645007371902466, -0.5683033466339111, 0.04104142263531685, -0.6397829651832581, 0.5793152451515198, -1.0385972261428833, -1.204174280166626, -0.43484461307525635, -0.3272216320037842, -0.7312397956848145, 0.19494368135929108, 0.3095948100090027, 0.6279206275939941, 0.14599460363388062, 1.6483054161071777, 0.43349146842956543, 0.9206019639968872, -0.2993567883968353, 0.36202284693717957, -0.024542421102523804, -0.15345649421215057, -0.8459853529930115, 0.640705943107605, -0.07387533038854599, -0.10724197328090668, -0.38201823830604553, -0.040322910994291306, -0.7041966915130615, -0.004747867584228516, -1.3559234142303467, 0.8064641952514648, -0.6488329172134399, -0.3421565890312195, 0.8984747529029846, -0.3483998477458954, -0.13104628026485443, 0.4171586036682129, 1.206929087638855, 0.19239357113838196, 0.1187996193766594, 0.3915184736251831, -0.6965457201004028, 0.11035816371440887, 0.28682053089141846, 0.032941535115242004, 0.4303094744682312, 0.8772478699684143, 0.25788554549217224, -0.044059835374355316, 0.7352597713470459, -0.04513063281774521, -0.13813458383083344, -0.13852183520793915, 0.17158640921115875, 0.8594222068786621, -0.33893299102783203, -1.0741488933563232, -0.5559128522872925, -0.005421862471848726, 0.8227444887161255, 0.10910312086343765, 0.3887344300746918, -0.13712286949157715, 0.6654520630836487, 0.3424522280693054, -0.9176685810089111, 0.048392608761787415, -0.4098077416419983, -0.2937941253185272, -0.19459009170532227, -0.5855845212936401, -0.318516343832016, 0.5612550973892212, 0.10140884667634964, 0.1735946536064148, 0.054711371660232544, 0.3588976263999939, 0.5992576479911804, 0.18270158767700195, -0.5199711918830872, -0.11162669956684113, 0.20713695883750916, -0.4804302752017975, -0.19396957755088806, 1.5882270336151123, 0.6037752032279968, -0.6228736042976379, 0.08970236778259277, -0.3465955853462219, -0.5285281538963318, 0.81485915184021, -0.13015416264533997, -0.22152113914489746, -0.18039871752262115, -0.16030754148960114, -0.6557562947273254, -0.1938805878162384, -0.20800098776817322, -0.14264072477817535, -0.8841832876205444, -0.03245193511247635, -0.8217737674713135, 0.6481607556343079, 0.11638884991407394, -0.2826727032661438, 0.5486035346984863, 0.3599020838737488, 0.14949385821819305, -0.5809463262557983, 0.2204095870256424, -0.17810024321079254, -0.4573383629322052, 0.8740501403808594, 0.4112519323825836, 0.10055338591337204, -0.6472885608673096, -0.3558046221733093, -0.15416517853736877, 0.4811650514602661, 0.5298316478729248, -1.0989549160003662, 0.8582146167755127, -0.10323989391326904, -0.40242260694503784, 0.24676084518432617, -0.779255747795105, -0.39824801683425903, -0.40866219997406006, 0.1690361052751541, 0.5816421508789062, 0.3499164283275604, -1.2990256547927856, -0.20333492755889893, -0.23999851942062378, 0.38623762130737305, -1.2531611919403076, -1.053071141242981, -1.3792228698730469, -0.43503230810165405, -0.540141224861145, 0.06256186962127686, -0.3975529074668884, 0.46194082498550415, 0.16386203467845917, -0.10682517290115356, -0.1934160739183426, -1.355631709098816, -1.0883729457855225, -1.0209028720855713, -0.24291884899139404, 0.1610955148935318, 0.30605244636535645, -1.0966172218322754, 0.5396613478660583, 0.22442728281021118, 0.4507720172405243, -0.421825647354126, -0.1997700333595276, 0.7341122627258301, 0.37478533387184143, 0.42049843072891235, 0.08244350552558899, -0.23248448967933655, 0.46801114082336426, -0.044544097036123276, 0.6591598987579346, 0.02679787576198578, -0.4025030732154846, 0.6786972284317017, -0.25756385922431946, 0.09552203863859177, -0.20731845498085022, 0.2193988412618637, 0.5897656083106995, -0.9939953088760376, -0.12051454931497574, 0.26600080728530884, 0.20279164612293243, 0.13258835673332214, 0.47575148940086365, -0.6286651492118835, 0.06685846298933029, -0.454923152923584, 0.4153440594673157, 0.9767033457756042, -0.6603468656539917, 0.14229604601860046, -0.5868972539901733, -0.6402814984321594, -0.9429103136062622, -0.4385770857334137, 0.14820922911167145, -0.6754635572433472, -0.06125961244106293, -0.05061781406402588, 0.11796094477176666, 0.27562272548675537, 0.5458707213401794, -0.23682665824890137, 0.05002520978450775, -0.3887981176376343, 0.11785338819026947, 0.8010765314102173, 0.764428973197937, 0.15160013735294342, 1.1474432945251465, 1.3471016883850098, -0.19378384947776794, 1.095882534980774, -1.006667137145996, -0.7247271537780762, -0.39283302426338196, -0.32667386531829834, -0.25406694412231445, 0.10737261176109314, -0.5495575666427612, 0.8765221834182739, 0.9537016153335571, -0.8434762954711914, -0.5469896197319031, -0.1007276326417923, 0.1435098648071289, 0.07170072197914124, 0.6278771162033081, -0.41660982370376587, 0.9186431169509888, -0.23776620626449585, -0.34145137667655945, -0.10098710656166077, -0.07077620178461075, -0.14701062440872192, 0.35888567566871643, -0.28138771653175354, 0.12120616436004639, 0.6182386875152588, -0.2486322969198227, 0.2679929733276367, 0.4234781265258789, -0.42550918459892273, -0.15372604131698608, 0.4571657180786133, -0.8222920894622803, -0.2119641900062561, 0.2841860353946686, 0.7746902108192444, -0.0910835713148117, -0.42764735221862793, -0.2900806963443756, -0.4080505073070526, -0.1200849711894989, 0.6657524108886719, -0.7117671966552734, 0.3911273181438446, 0.5526182651519775, 0.8969594240188599, -0.162600576877594, 0.434922456741333, 0.38444769382476807, 0.11980738490819931, -1.0151665210723877, -0.3241058886051178, 0.3591957688331604, 0.01149461604654789, -0.6299712061882019, 0.03368210420012474, 0.011038541793823242, -0.09519489854574203, -0.13862398266792297, -0.1967211216688156, -0.0717003121972084, 0.21626046299934387, -0.7840982675552368, -0.18140096962451935, 1.540311574935913, -0.3381979763507843, 0.6403213739395142, 0.561514139175415, 0.6417675018310547, 1.062565565109253, -0.805944561958313, -0.5242420434951782, 0.40349090099334717, -0.35821932554244995, -0.24793338775634766, -0.22951601445674896, 0.3021223545074463, 0.3256405293941498, 0.32454222440719604, 0.16554108262062073, 0.38297557830810547, 0.3696950674057007, -0.5042454600334167, -0.34357601404190063, -0.8017621636390686, -0.18797501921653748, -1.186662197113037, 0.2833064794540405, -0.8257733583450317, -0.5180450677871704, -0.40768519043922424, 0.4226377308368683, -0.26088008284568787, -0.4846971929073334, -0.29593807458877563, -0.7912799715995789, -0.10139207541942596, -0.28587251901626587, 0.05702543631196022, 0.6066495180130005, 0.11345097422599792, 0.3676312565803528, -0.07138897478580475, -0.01320713385939598, -1.176187515258789, 0.6110066175460815, 0.7644073367118835, 0.7059776782989502, 0.154555082321167, -0.07403260469436646, 0.6235520243644714, -0.30334314703941345, -0.1693737804889679, 0.3640955090522766, 0.029672138392925262, 0.2949541211128235, 0.01534917950630188, 0.1779533177614212, -0.37970519065856934, 0.4734547734260559, -0.48315176367759705, -0.19618648290634155, -0.2822779417037964, -0.7472594976425171, 0.9151026606559753, -0.3948324918746948, -0.5971738696098328, -0.6972901821136475, -0.7185112237930298, -0.5912289023399353, 1.153672218322754, -0.4456188678741455, 0.5674476027488708, -0.09295918047428131, 0.6884387731552124, 0.051104381680488586, 0.14258775115013123, -0.6654244661331177, 0.06122811883687973, -0.14863650500774384, 0.3461689352989197, 0.9445263147354126, -1.1672775745391846, -0.3881855607032776, 0.6503570675849915, -0.6914904117584229, -0.16190998256206512, -0.1281827986240387, -0.7056790590286255, 0.20546835660934448, -0.8842405676841736, 0.21948903799057007, -0.6928690075874329, 1.251103401184082, 0.44776177406311035, 0.2452719509601593, -0.4349140524864197, 0.9662575721740723, 0.25061842799186707, 0.9657374620437622, 0.2620941996574402, -0.6704882979393005, -0.5483412742614746, -0.5083097815513611, 0.39038702845573425, 0.4447897970676422, -0.15244480967521667, -0.1390053629875183, 0.03320435807108879, 0.40962356328964233, 0.04751766845583916, 0.6391101479530334, -0.2117118537425995, 0.07264237105846405, -0.02625679224729538, -0.1511177122592926, -0.3886875510215759, 0.7149559259414673, -0.4537314176559448, 0.09102664887905121, 1.2696633338928223, 0.28275948762893677, -0.19090090692043304, -0.9670835733413696, 0.08049555122852325, -0.2968765199184418, 0.804960310459137, 0.4037961959838867, 0.9450646638870239, 0.37899109721183777, 0.39404061436653137, -0.3827086091041565, 0.4070824682712555, -0.5196090936660767, -0.23482660949230194, -0.5049393177032471, 1.2280678749084473, 0.21595126390457153, 0.6332305669784546, 0.49079811573028564, -0.3573693633079529, 0.24305355548858643, 0.7730671167373657, -0.4016214907169342, 0.6194545030593872, 0.7147162556648254, -0.8297509551048279, -0.17172054946422577, 1.290744662284851, -0.6422756910324097, 0.34904181957244873, -0.026439107954502106, 0.19048187136650085, -0.4065898656845093, 0.1704576164484024, 0.2084057629108429, -1.0678420066833496, 0.203305184841156, 0.6009855270385742, -0.09186050295829773, -0.9417567253112793, -1.1362948417663574, 1.06882905960083, -0.2699123024940491, 0.1823245733976364, -0.3466036319732666, 0.722533106803894, 0.3830186724662781, 0.8311667442321777, 0.3012099862098694, -0.5535925626754761, -0.7667202353477478, -0.34788015484809875, 0.30485549569129944, 0.47727441787719727, -0.44557690620422363, 0.35938602685928345, -0.07661731541156769, 0.5254388451576233, -0.3809993267059326, -0.5801509618759155, 0.06917063891887665, 0.24824638664722443, 0.2741643190383911, -0.03430456668138504, -0.20756886899471283, 0.3351520299911499, 0.22461536526679993, -0.7060757875442505, -0.43671977519989014, 0.4440169036388397, -0.5711302161216736, -0.7250628471374512, 0.22179986536502838, -0.353503555059433, 0.2303503006696701, -0.3018035590648651, -0.9161185026168823, 0.3276762068271637, -0.02408323809504509, -0.18545997142791748, 0.11237430572509766, -0.7890656590461731, 0.014716866426169872, -0.20247840881347656, -0.3833485245704651, -0.309909850358963, 0.0598730631172657, -0.15114040672779083, -0.8838487863540649, -0.010441388934850693, 0.053858283907175064, 0.04323463886976242, 0.05431713908910751, -0.4621897041797638, 0.619423508644104, 0.5946421027183533, -0.13439223170280457, 0.29741984605789185, -0.6150087118148804, -0.02945874258875847, -0.06887058168649673, 0.6202459931373596, 0.0769127681851387, 0.011363476514816284, 0.08911128342151642, 0.36889272928237915, -0.3055027723312378, -0.36201614141464233, 0.4225103259086609, -0.7823551893234253, 0.6180226802825928, 0.035625159740448, 0.05183732137084007, 0.2572607696056366, -0.6236768364906311, 0.019495297223329544, -0.47759172320365906, 0.08814232796430588, 0.11353980004787445, -0.21373094618320465, 0.4820157289505005, -0.530165433883667, 0.3572114408016205, -0.006939977407455444, 0.532977819442749, 0.9400647282600403, -0.5071768164634705, 0.009749742224812508, 0.10522621870040894, -0.24720808863639832, 0.029749389737844467, -0.12910717725753784, -0.3587217330932617, 0.03602542728185654, -0.7936422824859619, -0.2721651494503021, -0.12844260036945343, -0.6335858106613159, 0.31466609239578247, 0.27727827429771423, -0.22879329323768616, -0.34451842308044434, 0.555060625076294, -0.1417568176984787, 0.6493309736251831, -0.59770268201828, 0.11446765810251236, -0.7243600487709045, 0.0035884901881217957, 0.3400203287601471, -0.1832079291343689, -0.8200935125350952, -0.9370441436767578, -0.4345482289791107, 0.8578616380691528, -0.7490471601486206, 0.3775778114795685, 1.1067159175872803, 0.12932683527469635, -0.767382025718689, 0.6447614431381226, 0.19041302800178528, 0.7011246085166931, 0.3850353956222534, 0.33460521697998047, 0.2739151120185852, -0.15491852164268494, -0.3436051607131958, -0.6985032558441162, 0.981439471244812, -0.32527852058410645, 0.00760265439748764, -0.8440046906471252, 0.20684057474136353, 0.9845230579376221, -0.5173044800758362, -0.8042851686477661, 0.11457843333482742, -0.6202514171600342, -0.06168200448155403, 0.38623958826065063, 0.29719313979148865, 0.6430617570877075, -0.43464651703834534, 0.1559373438358307, 0.22013749182224274, -0.1057572066783905, -0.42387375235557556, -0.26384419202804565, -0.30416783690452576, -0.584912121295929, -1.0699658393859863, 0.47591960430145264, -0.2487720251083374, -0.703294575214386, 0.5198549032211304, -1.6309067010879517, -0.6850117444992065, 0.0032151639461517334, -0.3908274173736572, -0.36717209219932556, -0.38699179887771606, -0.3065454959869385, 0.2353430688381195, -0.877038300037384, -0.31098026037216187, 0.13171392679214478, 0.6973066926002502, -0.04661950841546059, 1.385430097579956, -0.23586314916610718, 0.2456488013267517, -0.4708016812801361, -0.023609153926372528, -0.49978262186050415, 0.07943122833967209], 'response': ''}, 'sort': [2]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3597403/2469981258.py:45: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = client.knn_search(\n",
      "/tmp/ipykernel_3597403/2469981258.py:45: ElasticsearchWarning: The kNN search API has been replaced by the `knn` option in the search API.\n",
      "  response = client.knn_search(\n"
     ]
    }
   ],
   "source": [
    "def question_cache(question: str) -> dict[str, float|str]:\n",
    "    question_vector = embedder.encode(question, convert_to_numpy=True).tolist()\n",
    "    search_results = vector_search(client, content_vector=question_vector)\n",
    "\n",
    "    search_results = list(search_results)\n",
    "\n",
    "    # for i in search_results:\n",
    "    #     print(i)\n",
    "\n",
    "    if len(search_results) == 0:\n",
    "        # send_to_elasticsearch(client, documents, index=\"my_doc_dense_index\")\n",
    "        return None\n",
    "    if len(search_results) > 0:\n",
    "        # print(\"Search results = \", json.dumps({\"similarity_score\": search_results[0][\"_score\"], \"question\": search_results[0][\"_source\"][\"content\"]}, indent=4))\n",
    "        required_doc = list(find_document_by_id(client, search_results[0][\"_id\"]))[0]\n",
    "        # for i in required_doc:\n",
    "        #     print(json.dumps(i[\"_source\"][\"content\"], indent=4))\n",
    "        # print(\"\\n\\n\", json.dumps(required_doc[\"_source\"][\"content\"], indent=4))\n",
    "        \n",
    "        return required_doc\n",
    "\n",
    "print(question_cache(\"Tell me about Jeff Bezos\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, [])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# helpers.scan(\n",
    "#     client,\n",
    "    \n",
    "# )\n",
    "\n",
    "helpers.bulk(\n",
    "    client,\n",
    "    documents,\n",
    "    index=\"my_doc_dense_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search_result = helpers.scan(client,\n",
    "    query={\"query\": {\"match\": {\"content\": \"Tell me about Elon Musk\"}}},\n",
    "    # index=\"orders-*\",\n",
    "    index=\"my_doc_dense_index\",\n",
    "    # doc_type=\"books\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in search_result:\n",
    "#     print(json.dumps(i, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents[4][\"content_vector\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Playing around with Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting qdrant-client\n",
      "  Downloading qdrant_client-1.1.7-py3-none-any.whl (127 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.8/127.8 KB\u001b[0m \u001b[31m164.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<2.0,>=1.8 in /home/anuran/.local/lib/python3.10/site-packages (from qdrant-client) (1.9.1)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /home/anuran/.local/lib/python3.10/site-packages (from qdrant-client) (1.46.3)\n",
      "Collecting typing-extensions<5.0.0,>=4.0.0\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting grpcio-tools>=1.41.0\n",
      "  Downloading grpcio_tools-1.54.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /home/anuran/.local/lib/python3.10/site-packages (from qdrant-client) (1.21.2)\n",
      "Collecting urllib3<2.0.0,>=1.26.14\n",
      "  Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Collecting portalocker<3.0.0,>=2.7.0\n",
      "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting httpx[http2]>=0.14.0\n",
      "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 KB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/lib/python3/dist-packages (from grpcio>=1.41.0->qdrant-client) (1.16.0)\n",
      "Collecting grpcio>=1.41.0\n",
      "  Downloading grpcio-1.54.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (59.6.0)\n",
      "Collecting protobuf<5.0dev,>=4.21.6\n",
      "  Downloading protobuf-4.23.1-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna in /home/anuran/.local/lib/python3.10/site-packages (from httpx[http2]>=0.14.0->qdrant-client) (3.2)\n",
      "Requirement already satisfied: sniffio in /home/anuran/.local/lib/python3.10/site-packages (from httpx[http2]>=0.14.0->qdrant-client) (1.2.0)\n",
      "Collecting httpcore<0.18.0,>=0.15.0\n",
      "  Downloading httpcore-0.17.1-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.9/70.9 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /home/anuran/.local/lib/python3.10/site-packages (from httpx[http2]>=0.14.0->qdrant-client) (2021.5.30)\n",
      "Collecting h2<5,>=3\n",
      "  Using cached h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "Collecting hpack<5,>=4.0\n",
      "  Using cached hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Collecting hyperframe<7,>=6.0\n",
      "  Using cached hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/anuran/.local/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx[http2]>=0.14.0->qdrant-client) (0.13.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/anuran/.local/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx[http2]>=0.14.0->qdrant-client) (3.6.1)\n",
      "Installing collected packages: urllib3, typing-extensions, protobuf, portalocker, hyperframe, hpack, grpcio, httpcore, h2, grpcio-tools, httpx, qdrant-client\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.6\n",
      "    Uninstalling urllib3-1.26.6:\n",
      "      Successfully uninstalled urllib3-1.26.6\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.0\n",
      "    Uninstalling typing-extensions-3.10.0.0:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.4\n",
      "    Uninstalling protobuf-3.19.4:\n",
      "      Successfully uninstalled protobuf-3.19.4\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.46.3\n",
      "    Uninstalling grpcio-1.46.3:\n",
      "      Successfully uninstalled grpcio-1.46.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.12.0 requires torch==1.11.0, but you have torch 1.13.1 which is incompatible.\n",
      "tensorboardx 2.5.1 requires protobuf<=3.20.1,>=3.8.0, but you have protobuf 4.23.1 which is incompatible.\n",
      "tensorboard 2.9.1 requires google-auth-oauthlib<0.5,>=0.4.1, but you have google-auth-oauthlib 1.0.0 which is incompatible.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.23.1 which is incompatible.\n",
      "selenium 4.6.0 requires certifi>=2021.10.8, but you have certifi 2021.5.30 which is incompatible.\n",
      "jupyterlab-server 2.16.5 requires requests>=2.28, but you have requests 2.26.0 which is incompatible.\n",
      "gcsa 1.3.0 requires google-auth-oauthlib<0.5,>=0.4, but you have google-auth-oauthlib 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed grpcio-1.54.2 grpcio-tools-1.54.2 h2-4.1.0 hpack-4.0.0 httpcore-0.17.1 httpx-0.24.1 hyperframe-6.0.1 portalocker-2.7.0 protobuf-4.23.1 qdrant-client-1.1.7 typing-extensions-4.5.0 urllib3-1.26.15\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install qdrant-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "qdrant = QdrantClient(\"http://localhost:6333\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Qdrant API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FrugalGPT implementation\n",
    "\n",
    "This notebook implements [**FrugalGPT**](https://arxiv.org/pdf/2305.05176.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LLM Cascading Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "LLMS_TO_CASCADE: list[str] = [\n",
    "    # Format: (model_name, threshold)\n",
    "    (\"text-ada-001\", 0.5),\n",
    "    (\"ada\", 0.5),\n",
    "    (\"text-babbage-001\", 0.675),\n",
    "    (\"babbage\", 0.7),\n",
    "    (\"text-curie-001\", 0.725),\n",
    "    (\"curie\", 0.75),\n",
    "    (\"text-davinci-001\", 0.8),\n",
    "    (\"davinci\", 0.85),\n",
    "    (\"text-davinci-002\", 0.89),\n",
    "    (\"text-davinci-003\", 0.9),\n",
    "    (\"gpt-3.5-turbo\", 0.99),\n",
    "    # \"gpt-4\"  # Waitlist pending\n",
    "    # \"gpt-4-32k\"  # Waitlist pending\n",
    "] # Order must be from cheapest to most expensive LLM\n",
    "\n",
    "def scoring_function(x: np.ndarray):\n",
    "    return random.choice([0.9, 0.5, ])\n",
    "\n",
    "\n",
    "class CascadingLLMStrategy:\n",
    "    def __init__(self, LLMs: list[str]):\n",
    "        openai.api_key = \"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\"\n",
    "        self.llm_list: list[str] = LLMs\n",
    "        self.current_llm_index: int = 0\n",
    "\n",
    "    def query_llm(self, query: str):\n",
    "        response = None\n",
    "        try:\n",
    "            # response = openai.ChatCompletion(\n",
    "            # engine=self.llm_list[self.current_llm_index][0],\n",
    "            # message=[\n",
    "            #     {\n",
    "            #         \"role\": \"user\",\n",
    "            #         \"content\": query\n",
    "            #     }]\n",
    "            # )\n",
    "            \n",
    "            response = openai.Completion.create(\n",
    "              model=self.llm_list[self.current_llm_index][0],\n",
    "              prompt=query,\n",
    "              temperature=0.5,\n",
    "              max_tokens=150,\n",
    "              top_p=1,\n",
    "              frequency_penalty=0,\n",
    "              presence_penalty=0.6,\n",
    "              # stop=[\" Human:\", \" AI:\"]\n",
    "            )\n",
    "\n",
    "            res_json = response.to_dict_recursive()\n",
    "            print(res_json)\n",
    "            # return res_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "            return res_json[\"choices\"][0][\"text\"]\n",
    "        except KeyError as k:\n",
    "            print(\"Key error encountered! Invalid key = \", k)\n",
    "        except Exception as e:\n",
    "            print(\"Error Querying OpenAI API. Error:\")\n",
    "            print(e)\n",
    "            print(response)\n",
    "\n",
    "    def score_vector(self, x: np.ndarray):\n",
    "        return random.choice([0.9, 0.75, 0.5, 0.675, 0.875, 0.85, 0.99])\n",
    "\n",
    "    def cascade(self, by: int=1):\n",
    "        print(f\"Model last used = {self.llm_list[self.current_llm_index][0]}\")\n",
    "        self.current_llm_index += by\n",
    "        print(f\"Now using {self.llm_list[self.current_llm_index][0]}\")\n",
    "    \n",
    "    def execute(self, query):\n",
    "        score = -0.1  # Set initial score to zero\n",
    "        threshold_score = 0.0\n",
    "        response: str = \"\"\n",
    "        while (self.current_llm_index < len(self.llm_list)):\n",
    "            response = self.query_llm(query=query)\n",
    "            threshold_score = self.llm_list[self.current_llm_index][1]\n",
    "            score = self.score_vector(response)\n",
    "            print(f\"Score on model {self.llm_list[self.current_llm_index][0]} = {score}\")\n",
    "\n",
    "            if score > threshold_score:\n",
    "                break\n",
    "            self.cascade()\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cmpl-7K2pPbUtDPZ9rre70PyeTTOl0vifa', 'object': 'text_completion', 'created': 1685011787, 'model': 'text-ada-001', 'choices': [{'text': \"\\n\\nJeff Bezos is the founder and CEO of Amazon, which was founded in 1997. Amazon is a e-commerce and streetwear company that sells books, clothing, and other items online. Bezos was also the founder of The Washington Post, which is today's largest newspaper by circulation.\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 5, 'completion_tokens': 58, 'total_tokens': 63}}\n",
      "Key error encountered! Invalid key =  'message'\n",
      "Score on model ('text-ada-001', 0.5) = 0.675\n"
     ]
    }
   ],
   "source": [
    "cascading_strategy = CascadingLLMStrategy(LLMs=LLMS_TO_CASCADE)\n",
    "cascading_strategy.execute(\"Who is Jeff Bezos?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement LLM Query-Response Caching Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Query Mechanism\n",
    "\n",
    "The following cell implements the OpenAI API Query mechanism. This will be used while specifying the query mechanism for the Cache in case of Cache Miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def fetch_results(prompt: str) -> str:\n",
    "    response = openai.ChatCompletion.create(model='gpt-3.5-turbo', messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        # {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"}\n",
    "    ])\n",
    "\n",
    "    # return response\n",
    "\n",
    "    res_json = response.to_dict_recursive()\n",
    "\n",
    "\n",
    "    return res_json[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching Strategy\n",
    "\n",
    "The following cell implements the caching strategy as mentioned in the FrugalGPT paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from typing import Callable, Any, Dict, List\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class Cache:\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm_entrypoint: Callable[..., str] = lambda x: \"foo\",\n",
    "        similarity_threshold: float = 0.5\n",
    "    ):\n",
    "        self.embedder: SentenceTransformer = SentenceTransformer('bert-base-nli-stsb-mean-tokens', device=\"cpu\")\n",
    "        self.client: Elasticsearch = Elasticsearch(\"http://localhost:9200\") # self._connect_to_elasticsearch(url=\"http://localhost:9200\")\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.llm_entrypoint = llm_entrypoint\n",
    "\n",
    "    def _add_to_cache(self, documents: list[dict[str, Any]], index: str=\"my_doc_dense_index\") -> Any:\n",
    "        response = helpers.bulk(\n",
    "            self.client,\n",
    "            documents,\n",
    "            index=index\n",
    "        )\n",
    "        return response\n",
    "\n",
    "    def _connect_to_elasticsearch(self, **params):\n",
    "        try:\n",
    "            client = Elasticsearch(**params)\n",
    "            info = client.info()\n",
    "            return client\n",
    "        except:\n",
    "            raise Exception(\"Connection not established\")\n",
    "    \n",
    "    def _get_embeddings(self, query: str) -> np.array:\n",
    "        return self.embedder.encode(query, convert_to_numpy=True)\n",
    "\n",
    "    def _vector_search(self, content_vector: list[float]) -> dict:\n",
    "        # script_query = {\n",
    "        #     \"script_score\": {\n",
    "        #         \"query\": {\"match_all\": {}},\n",
    "        #         \"script\": {\n",
    "        #             \"source\": \"cosineSimilarity(params.query_vector, doc['content_vector'])\",\n",
    "        #             \"params\": {\"query_vector\": content_vector }\n",
    "        #         }\n",
    "        #     }\n",
    "        # }\n",
    "\n",
    "        script_query = {\n",
    "            \"knn\":{\n",
    "                \"k\": 10,\n",
    "                \"num_candidates\": 10,\n",
    "                \"field\": \"content_vector\",\n",
    "                \"query_vector\": content_vector\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # response = helpers.scan(\n",
    "        #     client,\n",
    "        #     index=\"my_doc_dense_index\",\n",
    "        #     body={\n",
    "        #         # \"size\": 10,\n",
    "        #         \"query\": script_query,\n",
    "        #         \"_source\": {\n",
    "        #             \"includes\": [\"content\"]\n",
    "        #         }\n",
    "        #     }\n",
    "        # )\n",
    "\n",
    "        response = self.client.knn_search(\n",
    "            body=script_query,\n",
    "            index=\"my_doc_dense_index\"\n",
    "        )[\"hits\"][\"hits\"]\n",
    "\n",
    "        return response\n",
    "\n",
    "    def _find_document_by_id(self, doc_id: Any) -> dict:\n",
    "        return helpers.scan(\n",
    "            self.client,\n",
    "            index=\"my_doc_dense_index\",\n",
    "            query={\n",
    "                \"query\": {\n",
    "                    \"match\": {\n",
    "                        \"_id\": doc_id\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def _question_cache(self, question: str) -> dict[str, float|str]:\n",
    "        question_vector = self.embedder.encode(question, convert_to_numpy=True).tolist()\n",
    "        search_results = self._vector_search(content_vector=question_vector)\n",
    "\n",
    "        search_results = list(search_results)\n",
    "\n",
    "        # for i in search_results:\n",
    "        #     print(i)\n",
    "\n",
    "        \n",
    "        if len(search_results) == 0:\n",
    "            # send_to_elasticsearch(client, documents, index=\"my_doc_dense_index\")\n",
    "            return {}\n",
    "        if len(search_results) > 0:\n",
    "            # print(\"Search results = \", json.dumps({\"similarity_score\": search_results[0][\"_score\"], \"question\": search_results[0][\"_source\"][\"content\"]}, indent=4))\n",
    "            best_response_score = search_results[0][\"_score\"]\n",
    "            \n",
    "            if best_response_score < self.similarity_threshold:\n",
    "                return {}\n",
    "\n",
    "            print(f\"Cache Hit - similarity found {best_response_score*100}% similar query\")\n",
    "            required_doc = list(self._find_document_by_id(search_results[0][\"_id\"]))[0][\"_source\"]\n",
    "            # print(\"Required Doc = \", json.dumps(required_doc, indent=4))\n",
    "            # for i in required_doc:\n",
    "            #     print(json.dumps(i[\"_source\"][\"content\"], indent=4))\n",
    "            # print(\"\\n\\n\", json.dumps(required_doc[\"_source\"][\"content\"], indent=4))\n",
    "\n",
    "            return {key: ele for key, ele in required_doc.items() if key in [\"content\", \"response\"]}\n",
    "\n",
    "    def _get_llm_response(self, query: str) -> str:\n",
    "        return self.llm_entrypoint(query)\n",
    "\n",
    "    def _execute(self, query: str):\n",
    "        query_embedding = self.embedder.encode(query, convert_to_numpy=True).tolist()\n",
    "        cache_result = self._question_cache(query)\n",
    "        if cache_result == {}:\n",
    "            llm_response = self._get_llm_response(query)\n",
    "            user_id = 1 # Sample user ID\n",
    "            content = query\n",
    "            content_vector = self._get_embeddings(content)\n",
    "            \n",
    "            document_to_add = {\n",
    "                \"content\": content,\n",
    "                \"response\": llm_response,\n",
    "                \"content_vector\": content_vector,\n",
    "                \"user_id\": user_id\n",
    "            }\n",
    "            \n",
    "            self._add_to_cache(documents=[document_to_add])\n",
    "        \n",
    "            return {\n",
    "                \"content\": content,\n",
    "                \"response\": llm_response\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"content\": cache_result[\"content\"],\n",
    "            \"response\": cache_result[\"response\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3597403/955262011.py:69: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = self.client.knn_search(\n",
      "/tmp/ipykernel_3597403/955262011.py:69: ElasticsearchWarning: The kNN search API has been replaced by the `knn` option in the search API.\n",
      "  response = self.client.knn_search(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': 'Who is Jeff Bezos?',\n",
       " 'response': 'Jeff Bezos is an American entrepreneur, investor, and philanthropist, best known as the founder, CEO, and chairman of Amazon.com, which is one of the largest online retailers in the world. He is considered the richest person on the planet with a net worth of over $150 billion. Bezos has also invested in other companies in various industries including space exploration through his company Blue Origin.'}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache = Cache(llm_entrypoint=fetch_results)\n",
    "\n",
    "cache._execute(\"Who is Jeff Bezos?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3597403/955262011.py:69: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = self.client.knn_search(\n",
      "/tmp/ipykernel_3597403/955262011.py:69: ElasticsearchWarning: The kNN search API has been replaced by the `knn` option in the search API.\n",
      "  response = self.client.knn_search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache Hit - similarity found 100.0% similar query\n",
      "Cache Hit - similarity found 100.0% similar query\n",
      "Cache Hit - similarity found 100.0% similar query\n",
      "Cache Hit - similarity found 100.0% similar query\n",
      "Cache Hit - similarity found 100.0% similar query\n",
      "Cache Hit - similarity found 100.0% similar query\n",
      "Cache Hit - similarity found 100.0% similar query\n",
      "Cache Hit - similarity found 100.0% similar query\n",
      "257 ms ± 22 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit cache._execute(\"Who is Jeff Bezos?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
